{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "653fe42c",
   "metadata": {},
   "source": [
    "We import the ICD codes and the dataset-specific codes, then encode them into embeddings using a transformer model. To visualize potential clusters to aid cleaning, we apply UMAP for dimensionality reduction and HDBSCAN for cluster detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "46ab3610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "from itertools import chain\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import glob\n",
    "\n",
    "icd_codes = pd.read_csv(\"../data/raw/all_icd_codes.csv\", dtype = str)\n",
    "dataset_codes = pd.read_csv(\"../data/raw/dataset_codes.csv\", dtype = str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "928a24f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate list of unique codes and their row origin index\n",
    "codes = list(set(dataset_codes.code))\n",
    "ref_codes = list(set(icd_codes.code))\n",
    "\n",
    "flattened_codes = []\n",
    "row_ids = []\n",
    "\n",
    " # We could look at a histogram\n",
    "for row_id, code in enumerate(codes):\n",
    "    split_codes = re.split(r\"[,&/\\\\\\s]+\", code)\n",
    "    for fc in split_codes:\n",
    "        if fc not in flattened_codes:\n",
    "            flattened_codes.append(fc)\n",
    "            row_ids.append(row_id)\n",
    "            \n",
    "# Filter out empty strings\n",
    "ref_codes = [rc for rc in ref_codes if rc]\n",
    "flattened_codes = [fc for fc in flattened_codes if fc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d2194305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find length of all the unique codes\n",
    "data = np.array([len(x) for x in flattened_codes if x])\n",
    "\n",
    "# Create a histogram\n",
    "# plt.hist(data,\n",
    "#          bins = 5,\n",
    "        #  edgecolor='black')\n",
    "# plt.show()\n",
    "# All are 3-8 characters long after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d10eb900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY 206 codes do not have perfect matches!\n",
    "# Update: with additional ICD dictionaries, ONLY 9 codes do not have perfect matches!\n",
    "flattened_set = set(flattened_codes)\n",
    "ref_set = set(ref_codes)\n",
    "\n",
    "matched_codes = list(flattened_set & ref_set)\n",
    "# print(len(flattened_set) - len(matched_codes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825da540",
   "metadata": {},
   "source": [
    "For the 205 codes, we will use embeddings and cosine similarity to help us match them <br> \n",
    "Nevermind! For the 9 codes, I'll just do stuff manually. <br>\n",
    "Nevermind, we can just remove the scientific notation codes from the code list, clean them, reinsert them, and then find the set difference and manually annotate (e14.1 = Diabetes mellitus with ketoacidosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9bbc32c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched_codes = list(flattened_set.difference(ref_set))\n",
    "flattened_codes = [i for i in flattened_codes if i not in unmatched_codes]\n",
    "\n",
    "unmatched_codes = [re.sub(r\"\\+\", \"\", re.sub(r\"(\\.[^a-z]*)(?=e)\", \"\", str(x))) for x in unmatched_codes]\n",
    "flattened_codes += unmatched_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "980b1aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "['e14.1']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "flattened_set = set(flattened_codes)\n",
    "ref_set = set(ref_codes)\n",
    "matched_codes = list(flattened_set & ref_set)\n",
    "\n",
    "print(len(flattened_set) - len(matched_codes))\n",
    "unmatched_codes = list(flattened_set.difference(ref_set))\n",
    "\n",
    "print(unmatched_codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4ab2d6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate - Now we can map all our codes\n",
    "icd_codes.loc[len(icd_codes)] = [\"e14.1\", \"Diabetes mellitus with ketoacidosis\"] # https://icd.who.int/browse10/2019/en#/E10-E14\n",
    "ref_set = list(set(icd_codes.code)) # For the comprehensive list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0dab7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "correction_1",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "correction_2",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "correction_3",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "correction_4",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "correction_5",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "correction_6",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "correction_7",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "correction_8",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "79b187f8-3208-4b77-9e69-5527377ab8ec",
       "rows": [
        [
         "0",
         "e14.1",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "1",
         "i95.9",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "2",
         "c53.9",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "3",
         "d64.9",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "4",
         "a41.9",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "5",
         "i50.0",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "6",
         "g03.9",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "7",
         "a16.9",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "8",
         "1g40",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "9",
         "ma18.0",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "10",
         "mg27",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "11",
         "mc82.4",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "12",
         "ca4z",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "13",
         "db9z",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "14",
         "db99.5",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "15",
         "3a9z",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "16",
         "1b10.z",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "17",
         "8e4y",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "18",
         "bd1z",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "19",
         "1d01.10",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "20",
         "ra01.0/ca40.1",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "21",
         "ra01.0",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "22",
         "2e05.0",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "23",
         "ca40.z",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "24",
         "cb00",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "25",
         "2c77.z",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "26",
         "mc82.z",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "27",
         "1g41",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "28",
         "na0z",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "29",
         "mg40.z",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "30",
         "ba00.z",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "31",
         "gb6z",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "32",
         "ne61",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "33",
         "r60",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "34",
         "ja43.z",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "35",
         "1d01.y",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "36",
         "1b13.z",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "37",
         "8a00.2y",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "38",
         "1b12.7",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "39",
         "i12.9",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "40",
         "ca23.31",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "41",
         "ca40.1z",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "42",
         "1f4z",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "43",
         "mg40.0",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "44",
         "2b6a.y",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "45",
         "5a41",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "46",
         "cb27",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "47",
         "md11.5",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "48",
         "2b33.5",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ],
        [
         "49",
         "5b7z",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         ""
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 2069
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>correction_1</th>\n",
       "      <th>correction_2</th>\n",
       "      <th>correction_3</th>\n",
       "      <th>correction_4</th>\n",
       "      <th>correction_5</th>\n",
       "      <th>correction_6</th>\n",
       "      <th>correction_7</th>\n",
       "      <th>correction_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e14.1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i95.9</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c53.9</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d64.9</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a41.9</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2064</th>\n",
       "      <td>ja00.36</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2065</th>\n",
       "      <td>8b60.z</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>nc7y</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>bb4y</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068</th>\n",
       "      <td>nb92.8</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2069 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         code correction_1 correction_2 correction_3 correction_4  \\\n",
       "0       e14.1                                                       \n",
       "1       i95.9                                                       \n",
       "2       c53.9                                                       \n",
       "3       d64.9                                                       \n",
       "4       a41.9                                                       \n",
       "...       ...          ...          ...          ...          ...   \n",
       "2064  ja00.36                                                       \n",
       "2065   8b60.z                                                       \n",
       "2066     nc7y                                                       \n",
       "2067     bb4y                                                       \n",
       "2068   nb92.8                                                       \n",
       "\n",
       "     correction_5 correction_6 correction_7 correction_8  \n",
       "0                                                         \n",
       "1                                                         \n",
       "2                                                         \n",
       "3                                                         \n",
       "4                                                         \n",
       "...           ...          ...          ...          ...  \n",
       "2064                                                      \n",
       "2065                                                      \n",
       "2066                                                      \n",
       "2067                                                      \n",
       "2068                                                      \n",
       "\n",
       "[2069 rows x 9 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# icd_codes.loc[icd_codes.code == \"e14.1\", :] # It's in\n",
    "\n",
    "# Create columns for corrections\n",
    "dataset_codes[\"correction_1\"] = \"\"\n",
    "dataset_codes[\"correction_2\"] = \"\"\n",
    "dataset_codes[\"correction_3\"] = \"\"\n",
    "dataset_codes[\"correction_4\"] = \"\"\n",
    "dataset_codes[\"correction_5\"] = \"\"\n",
    "dataset_codes[\"correction_6\"] = \"\"\n",
    "dataset_codes[\"correction_7\"] = \"\"\n",
    "dataset_codes[\"correction_8\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0627add",
   "metadata": {},
   "source": [
    "Great! Now we can \"back-propagate\" our corrections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7c51d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inefficient but not too slow. We compile and export the mapping dictionary.\n",
    "dataset_codes_2 = dataset_codes.copy()\n",
    "\n",
    "for i, r in dataset_codes_2.iterrows():\n",
    "    r_code = r.iloc[0]\n",
    "    r_splits = re.split(r\"[,&/\\\\\\s]+\", r_code)\n",
    "\n",
    "    for j, split in enumerate(r_splits):\n",
    "        if split: \n",
    "            if split in ref_set:\n",
    "                # print(split)\n",
    "                dataset_codes_2.loc[i, f'correction_{j+1}'] = split\n",
    "\n",
    "            elif split not in ref_set:\n",
    "                non_science_split = re.sub(r\"\\+\", \"\", re.sub(r\"(\\.[^a-z]*)(?=e)\", \"\", str(split))) \n",
    "                if non_science_split in ref_set:\n",
    "                    dataset_codes_2.loc[i, f'correction_{j+1}'] = non_science_split\n",
    "                else:\n",
    "                    print(\"Uh oh. No non-scientific-format match found:\")\n",
    "                    print(i)\n",
    "                    print(split)\n",
    "                    print()\n",
    "            else:\n",
    "                print(\"Uh oh. No match found:\")\n",
    "                print(i)\n",
    "                print(split)\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fbc731e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_codes_2.to_csv(\"../data/processed/code_to_code_dictionary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a490705",
   "metadata": {},
   "source": [
    "We have taken the OG strings, split them, and stored them in a dictionary; OG string: [splits]. Next, we will compare using embeddings (from SapBERT) and cosine similarity. Finally, we will try and reverse-match our OG strings to our dictionary of {reference : now_matched_code}. If we find no match, we split and compare each value in the split to the dictionary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c486c4",
   "metadata": {},
   "source": [
    "**Note** I actually didn't run the below; in the future, run it if you need to, save, and use those new (updated) reference embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2ea171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://huggingface.co/cambridgeltl/SapBERT-from-PubMedBERT-fulltext\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cambridgeltl/SapBERT-from-PubMedBERT-fulltext\")  \n",
    "model = AutoModel.from_pretrained(\"cambridgeltl/SapBERT-from-PubMedBERT-fulltext\").cuda()\n",
    "\n",
    "bs = 128 # batch size during inference\n",
    "unmatched_embeddings = []\n",
    "reference_embeddings = []\n",
    "\n",
    "for i in tqdm(np.arange(0, len(unmatched_codes), bs)):\n",
    "    toks = tokenizer.batch_encode_plus(unmatched_codes[i:i+bs], \n",
    "                                       padding=\"max_length\", \n",
    "                                       max_length=25, \n",
    "                                       truncation=True,\n",
    "                                       return_tensors=\"pt\")\n",
    "    toks_cuda = {}\n",
    "    for k,v in toks.items():\n",
    "        toks_cuda[k] = v.cuda()\n",
    "    cls_rep = model(**toks_cuda)[0][:,0,:] # use CLS representation as the embedding\n",
    "    unmatched_embeddings.append(cls_rep.cpu().detach().numpy())\n",
    "\n",
    "for i in tqdm(np.arange(0, len(ref_codes), bs)):\n",
    "    toks = tokenizer.batch_encode_plus(ref_codes[i:i+bs], \n",
    "                                       padding=\"max_length\", \n",
    "                                       max_length=25, \n",
    "                                       truncation=True,\n",
    "                                       return_tensors=\"pt\")\n",
    "    toks_cuda = {}\n",
    "    for k,v in toks.items():\n",
    "        toks_cuda[k] = v.cuda()\n",
    "    cls_rep = model(**toks_cuda)[0][:,0,:] # use CLS representation as the embedding\n",
    "    reference_embeddings.append(cls_rep.cpu().detach().numpy())\n",
    "\n",
    "unmatched_embeddings = np.concatenate(unmatched_embeddings, axis=0)\n",
    "reference_embeddings = np.concatenate(reference_embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b8e384",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"embeddings/unmatched_embeddings.npy\", unmatched_embeddings)\n",
    "np.save(\"embeddings/reference_embeddings.npy\", reference_embeddings)\n",
    "\n",
    "# # Load dataset code embeddings\n",
    "# unmatched_file = sorted(glob.glob(\"embeddings/unmatched_embeddings.npy\"))\n",
    "# unmatched_embeddings = np.vstack([np.load(f) for f in unmatched_file])\n",
    "\n",
    "# # Load reference code embeddings\n",
    "# references_file = sorted(glob.glob(\"embeddings/reference_embeddings.npy\"))\n",
    "# reference_embeddings = np.vstack([np.load(f) for f in references_file])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c109d89",
   "metadata": {},
   "source": [
    "Now, we use cosine similarity and edit distance to compare the codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bf1570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity matrix\n",
    "sim_matrix = cosine_similarity(unmatched_embeddings, reference_embeddings)\n",
    "\n",
    "# Get top-3 nearest reference codes for each dataset code\n",
    "top_k = 3\n",
    "top_matches = np.argsort(-sim_matrix, axis=1)[:, :top_k]\n",
    "\n",
    "for i, idxs in enumerate(top_matches):\n",
    "    print(f\"{row_ids[i]}: {unmatched_codes[i]} → {[ref_codes[j] for j in idxs]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a16c741",
   "metadata": {},
   "source": [
    "Note that for rows that end up with multiple codes, we will select the code it posseses that shows up with the highest frequency in the database."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
